# Acoustic_event_solution
STC ML school problem solving

## Описание решения
Используется [VGGish модель от Google Audioset](https://github.com/tensorflow/models/tree/master/research/audioset). С ее помощью получаются векторы признаков (окно 0.96 с, с шагом 0.96 с). Последовательность векторов семпла обрабатывается в [Shallow and wide CNN](https://arxiv.org/abs/1408.5882).


### Особенности
Берется не финальный слой VGGish, а только резльутат свертки (слой Flatten). Вектор большой размерности довольно долго обрабатывается в Shallow and wide CNN, но итоговое качество лучше.
CNN модель обучается в течение 20 эпох, затем выбырается лучшие веса по валидационной выборке. Регуляризацяи методом отсева + l2. Оптимизация параметров производится методом адаптивной инерции. Гиперпараметры подбирались по валидационной выборке. Валидационная выбока представляет из себя псевдо-случайно (random seed зафиксирован) выбранные 5% примеров из тренировачного набора данных. При этом выборе сохранялся баланс классов. В качестве примера при разбиении выступает семпл и все его аугментации (чтобы варианты одного примера не попали одновременно в трейн и валидацию).

### Подготовительные мероприятия
0) В консоле в корневой папке проекта запустить pip install -r requirements.txt
1) Скачать [tf версию предобученной модели](https://storage.googleapis.com/audioset/vggish_model.ckpt)
2) Положить vggish_model.ckpt в папку models
3) В папку data распаковать содержимое архива с конкурсными данными

### Получить решение
1) В консоле в корневой папке проекта набрать python train.py (можно пропустить, в папке model уже лежит обученная модель, результат повторяемый, поэтому для чистоты эксперимента ее лучше удалить перед повторением обучения)
2) В консоле в корневой папке проекта набрать python eval.py (решение закрытой задачи и открытой задачи). Лучшая модель будет выбрана автоматически.
3) Результат будет в result.txt.
 